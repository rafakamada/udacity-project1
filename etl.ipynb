{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ETL Processes\n",
    "Use this notebook to develop the ETL process for each of your tables before completing the `etl.py` file to load the whole datasets."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sql_queries import *"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "cur = conn.cursor()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def get_files(filepath):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    \n",
    "    return all_files"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process `song_data`\n",
    "In this first part, you'll perform ETL on the first dataset, `song_data`, to create the `songs` and `artists` dimensional tables.\n",
    "\n",
    "Let's perform ETL on a single song file and load a single record into each table to start.\n",
    "- Use the `get_files` function provided above to get a list of all song JSON files in `data/song_data`\n",
    "- Select the first song in this list\n",
    "- Read the song file and view the data"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "song_files = get_files('data/song_data')"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "filepath = song_files[0]"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df = pd.read_json(filepath, lines=True)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_songs</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AROUOZZ1187B9ABE51</td>\n",
       "      <td>40.79195</td>\n",
       "      <td>-73.94512</td>\n",
       "      <td>New York, NY [Spanish Harlem]</td>\n",
       "      <td>Willie Bobo</td>\n",
       "      <td>SOBZBAZ12A6D4F8742</td>\n",
       "      <td>Spanish Grease</td>\n",
       "      <td>168.25424</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_songs           artist_id  artist_latitude  artist_longitude  \\\n",
       "0          1  AROUOZZ1187B9ABE51         40.79195         -73.94512   \n",
       "\n",
       "                 artist_location  artist_name             song_id  \\\n",
       "0  New York, NY [Spanish Harlem]  Willie Bobo  SOBZBAZ12A6D4F8742   \n",
       "\n",
       "            title   duration  year  \n",
       "0  Spanish Grease  168.25424  1997  "
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #1: `songs` Table\n",
    "#### Extract Data for Songs Table\n",
    "- Select columns for song ID, title, artist ID, year, and duration\n",
    "- Use `df.values` to select just the values from the dataframe\n",
    "- Index to select the first (only) record in the dataframe\n",
    "- Convert the array to a list and set it to `song_data`"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "song_data = df[['song_id', 'title', 'artist_id', 'year', 'duration']].values\n",
    "song_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['SOBZBAZ12A6D4F8742', 'Spanish Grease', 'AROUOZZ1187B9ABE51',\n",
       "        1997, 168.25424]], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Insert Record into Song Table\n",
    "Implement the `song_table_insert` query in `sql_queries.py` and run the cell below to insert a record for this song into the `songs` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `songs` table in the sparkify database."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "song_table_insert"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nINSERT INTO songs\\n(id, title, artist_id, year, duration)\\nVALUES(%s, %s, %s, %s, %s)\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "cur.execute(song_table_insert, song_data[0])\n",
    "conn.commit()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run `test.ipynb` to see if you've successfully added a record to this table."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #2: `artists` Table\n",
    "#### Extract Data for Artists Table\n",
    "- Select columns for artist ID, name, location, latitude, and longitude\n",
    "- Use `df.values` to select just the values from the dataframe\n",
    "- Index to select the first (only) record in the dataframe\n",
    "- Convert the array to a list and set it to `artist_data`"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_songs</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AROUOZZ1187B9ABE51</td>\n",
       "      <td>40.79195</td>\n",
       "      <td>-73.94512</td>\n",
       "      <td>New York, NY [Spanish Harlem]</td>\n",
       "      <td>Willie Bobo</td>\n",
       "      <td>SOBZBAZ12A6D4F8742</td>\n",
       "      <td>Spanish Grease</td>\n",
       "      <td>168.25424</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_songs           artist_id  artist_latitude  artist_longitude  \\\n",
       "0          1  AROUOZZ1187B9ABE51         40.79195         -73.94512   \n",
       "\n",
       "                 artist_location  artist_name             song_id  \\\n",
       "0  New York, NY [Spanish Harlem]  Willie Bobo  SOBZBAZ12A6D4F8742   \n",
       "\n",
       "            title   duration  year  \n",
       "0  Spanish Grease  168.25424  1997  "
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "artist_data = df[['artist_id', 'artist_name', 'artist_location', 'artist_latitude', 'artist_longitude']].values\n",
    "artist_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['AROUOZZ1187B9ABE51', 'Willie Bobo',\n",
       "        'New York, NY [Spanish Harlem]', 40.79195, -73.94512]],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Insert Record into Artist Table\n",
    "Implement the `artist_table_insert` query in `sql_queries.py` and run the cell below to insert a record for this song's artist into the `artists` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `artists` table in the sparkify database."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "cur.execute(artist_table_insert, artist_data[0])\n",
    "conn.commit()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run `test.ipynb` to see if you've successfully added a record to this table."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process `log_data`\n",
    "In this part, you'll perform ETL on the second dataset, `log_data`, to create the `time` and `users` dimensional tables, as well as the `songplays` fact table.\n",
    "\n",
    "Let's perform ETL on a single log file and load a single record into each table.\n",
    "- Use the `get_files` function provided above to get a list of all log JSON files in `data/log_data`\n",
    "- Select the first log file in this list\n",
    "- Read the log file and view the data"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "log_files = get_files('data/log_data')"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "filepath = log_files[0]"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "df = pd.read_json(filepath, lines=True) \n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great Lake Swimmers</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Arellano</td>\n",
       "      <td>215.11791</td>\n",
       "      <td>free</td>\n",
       "      <td>Harrisburg-Carlisle, PA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540007e+12</td>\n",
       "      <td>815</td>\n",
       "      <td>Your Rocky Spine</td>\n",
       "      <td>200</td>\n",
       "      <td>1542931645796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soziedad Alkoholika</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Arellano</td>\n",
       "      <td>204.74730</td>\n",
       "      <td>free</td>\n",
       "      <td>Harrisburg-Carlisle, PA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540007e+12</td>\n",
       "      <td>815</td>\n",
       "      <td>Va Bien</td>\n",
       "      <td>200</td>\n",
       "      <td>1542931860796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Franz Ferdinand</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Arellano</td>\n",
       "      <td>172.01587</td>\n",
       "      <td>free</td>\n",
       "      <td>Harrisburg-Carlisle, PA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540007e+12</td>\n",
       "      <td>815</td>\n",
       "      <td>Eleanor Put Your Boots On</td>\n",
       "      <td>200</td>\n",
       "      <td>1542932064796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Modest Mouse</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Arellano</td>\n",
       "      <td>209.52771</td>\n",
       "      <td>free</td>\n",
       "      <td>Harrisburg-Carlisle, PA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540007e+12</td>\n",
       "      <td>815</td>\n",
       "      <td>Float On</td>\n",
       "      <td>200</td>\n",
       "      <td>1542932236796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam Lambert</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>Arellano</td>\n",
       "      <td>266.44853</td>\n",
       "      <td>free</td>\n",
       "      <td>Harrisburg-Carlisle, PA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540007e+12</td>\n",
       "      <td>815</td>\n",
       "      <td>Aftermath</td>\n",
       "      <td>200</td>\n",
       "      <td>1542932445796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist       auth firstName gender  itemInSession  lastName  \\\n",
       "0  Great Lake Swimmers  Logged In     Kevin      M              0  Arellano   \n",
       "1  Soziedad Alkoholika  Logged In     Kevin      M              1  Arellano   \n",
       "2      Franz Ferdinand  Logged In     Kevin      M              2  Arellano   \n",
       "3         Modest Mouse  Logged In     Kevin      M              3  Arellano   \n",
       "4         Adam Lambert  Logged In     Kevin      M              4  Arellano   \n",
       "\n",
       "      length level                 location method      page  registration  \\\n",
       "0  215.11791  free  Harrisburg-Carlisle, PA    PUT  NextSong  1.540007e+12   \n",
       "1  204.74730  free  Harrisburg-Carlisle, PA    PUT  NextSong  1.540007e+12   \n",
       "2  172.01587  free  Harrisburg-Carlisle, PA    PUT  NextSong  1.540007e+12   \n",
       "3  209.52771  free  Harrisburg-Carlisle, PA    PUT  NextSong  1.540007e+12   \n",
       "4  266.44853  free  Harrisburg-Carlisle, PA    PUT  NextSong  1.540007e+12   \n",
       "\n",
       "   sessionId                       song  status             ts  \\\n",
       "0        815           Your Rocky Spine     200  1542931645796   \n",
       "1        815                    Va Bien     200  1542931860796   \n",
       "2        815  Eleanor Put Your Boots On     200  1542932064796   \n",
       "3        815                   Float On     200  1542932236796   \n",
       "4        815                  Aftermath     200  1542932445796   \n",
       "\n",
       "                                           userAgent userId  \n",
       "0  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     66  \n",
       "1  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     66  \n",
       "2  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     66  \n",
       "3  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     66  \n",
       "4  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     66  "
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #3: `time` Table\n",
    "#### Extract Data for Time Table\n",
    "- Filter records by `NextSong` action\n",
    "- Convert the `ts` timestamp column to datetime\n",
    "  - Hint: the current timestamp is in milliseconds\n",
    "- Extract the timestamp, hour, day, week of year, month, year, and weekday from the `ts` column and set `time_data` to a list containing these values in order\n",
    "  - Hint: use pandas' [`dt` attribute](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.html) to access easily datetimelike properties.\n",
    "- Specify labels for these columns and set to `column_labels`\n",
    "- Create a dataframe, `time_df,` containing the time data for this file by combining `column_labels` and `time_data` into a dictionary and converting this into a dataframe"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import datetime\n",
    "df = df[df.page == 'NextSong']\n",
    "df.ts = df.ts.apply(lambda x : datetime.datetime.fromtimestamp(x/1000))\n",
    "df['hour'] = df.ts.dt.hour\n",
    "df['day'] = df.ts.dt.day\n",
    "df['week'] = df.ts.dt.isocalendar().week\n",
    "df['month'] = df.ts.dt.month\n",
    "df['year'] = df.ts.dt.year\n",
    "df['weekday'] = df.ts.dt.weekday\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>...</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great Lake Swimmers</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Arellano</td>\n",
       "      <td>215.11791</td>\n",
       "      <td>free</td>\n",
       "      <td>Harrisburg-Carlisle, PA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>2018-11-22 22:07:25.796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soziedad Alkoholika</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Arellano</td>\n",
       "      <td>204.74730</td>\n",
       "      <td>free</td>\n",
       "      <td>Harrisburg-Carlisle, PA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>2018-11-22 22:11:00.796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Franz Ferdinand</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Arellano</td>\n",
       "      <td>172.01587</td>\n",
       "      <td>free</td>\n",
       "      <td>Harrisburg-Carlisle, PA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>2018-11-22 22:14:24.796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Modest Mouse</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Arellano</td>\n",
       "      <td>209.52771</td>\n",
       "      <td>free</td>\n",
       "      <td>Harrisburg-Carlisle, PA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>2018-11-22 22:17:16.796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam Lambert</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>Arellano</td>\n",
       "      <td>266.44853</td>\n",
       "      <td>free</td>\n",
       "      <td>Harrisburg-Carlisle, PA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>2018-11-22 22:20:45.796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist       auth firstName gender  itemInSession  lastName  \\\n",
       "0  Great Lake Swimmers  Logged In     Kevin      M              0  Arellano   \n",
       "1  Soziedad Alkoholika  Logged In     Kevin      M              1  Arellano   \n",
       "2      Franz Ferdinand  Logged In     Kevin      M              2  Arellano   \n",
       "3         Modest Mouse  Logged In     Kevin      M              3  Arellano   \n",
       "4         Adam Lambert  Logged In     Kevin      M              4  Arellano   \n",
       "\n",
       "      length level                 location method  ... status  \\\n",
       "0  215.11791  free  Harrisburg-Carlisle, PA    PUT  ...    200   \n",
       "1  204.74730  free  Harrisburg-Carlisle, PA    PUT  ...    200   \n",
       "2  172.01587  free  Harrisburg-Carlisle, PA    PUT  ...    200   \n",
       "3  209.52771  free  Harrisburg-Carlisle, PA    PUT  ...    200   \n",
       "4  266.44853  free  Harrisburg-Carlisle, PA    PUT  ...    200   \n",
       "\n",
       "                       ts                                          userAgent  \\\n",
       "0 2018-11-22 22:07:25.796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...   \n",
       "1 2018-11-22 22:11:00.796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...   \n",
       "2 2018-11-22 22:14:24.796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...   \n",
       "3 2018-11-22 22:17:16.796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...   \n",
       "4 2018-11-22 22:20:45.796  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...   \n",
       "\n",
       "  userId  hour day week month  year  weekday  \n",
       "0     66    22  22   47    11  2018        3  \n",
       "1     66    22  22   47    11  2018        3  \n",
       "2     66    22  22   47    11  2018        3  \n",
       "3     66    22  22   47    11  2018        3  \n",
       "4     66    22  22   47    11  2018        3  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#time_data = ()\n",
    "#column_labels = ()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "time_df = df[['ts', 'hour', 'day', 'week', 'month', 'year', 'weekday']]\n",
    "time_df = time_df.rename(columns={'ts' : 'time_data'})\n",
    "time_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_data</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-22 22:07:25.796</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-22 22:11:00.796</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-22 22:14:24.796</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-22 22:17:16.796</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-22 22:20:45.796</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                time_data  hour  day  week  month  year  weekday\n",
       "0 2018-11-22 22:07:25.796    22   22    47     11  2018        3\n",
       "1 2018-11-22 22:11:00.796    22   22    47     11  2018        3\n",
       "2 2018-11-22 22:14:24.796    22   22    47     11  2018        3\n",
       "3 2018-11-22 22:17:16.796    22   22    47     11  2018        3\n",
       "4 2018-11-22 22:20:45.796    22   22    47     11  2018        3"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Insert Records into Time Table\n",
    "Implement the `time_table_insert` query in `sql_queries.py` and run the cell below to insert records for the timestamps in this log file into the `time` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `time` table in the sparkify database."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "for i, row in time_df.iterrows():\n",
    "    cur.execute(time_table_insert, list(row))\n",
    "    conn.commit()\n",
    "    print(list(row))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Timestamp('2018-11-22 22:07:25.796000'), 22, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-22 22:11:00.796000'), 22, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-22 22:14:24.796000'), 22, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-22 22:17:16.796000'), 22, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-22 22:20:45.796000'), 22, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-22 22:25:11.796000'), 22, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-22 22:29:30.796000'), 22, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-22 22:33:55.796000'), 22, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-22 22:38:05.796000'), 22, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-22 22:42:32.796000'), 22, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-22 22:45:07.796000'), 22, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-22 22:49:02.796000'), 22, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-22 23:34:56.796000'), 23, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-22 23:39:24.796000'), 23, 22, 47, 11, 2018, 3]\n",
      "[Timestamp('2018-11-23 00:35:36.796000'), 0, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 00:39:36.796000'), 0, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 01:48:24.796000'), 1, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 01:52:36.796000'), 1, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 01:57:58.796000'), 1, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 02:01:13.796000'), 2, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 02:04:51.796000'), 2, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 02:06:21.796000'), 2, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 02:09:56.796000'), 2, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 03:56:58.796000'), 3, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 04:03:11.796000'), 4, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 04:07:58.796000'), 4, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 04:09:06.796000'), 4, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 04:11:42.796000'), 4, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 04:15:22.796000'), 4, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 04:28:16.796000'), 4, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 05:05:36.796000'), 5, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 05:34:02.796000'), 5, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 05:50:40.796000'), 5, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 05:51:37.796000'), 5, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 05:53:57.796000'), 5, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 05:55:00.796000'), 5, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 08:39:09.796000'), 8, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 08:43:47.796000'), 8, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 08:57:19.796000'), 8, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:02:35.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:04:05.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:13:30.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:14:28.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:17:50.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:22:40.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:26:29.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:32:17.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:35:48.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:37:44.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:39:45.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:42:52.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:43:31.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:47:14.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:50:36.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:52:40.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:54:21.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 09:59:10.796000'), 9, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:01:25.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:02:53.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:05:04.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:07:58.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:08:33.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:11:58.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:12:48.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:15:42.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:17:20.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:21:09.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:23:40.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:28:13.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:30:30.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:33:54.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:34:55.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:37:42.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:38:30.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:42:12.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:42:26.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:46:07.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:46:24.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:50:21.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:50:45.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:51:36.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:52:33.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:54:29.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:54:50.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 10:58:04.796000'), 10, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 11:04:00.796000'), 11, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 12:25:06.796000'), 12, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 12:27:50.796000'), 12, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 12:38:54.796000'), 12, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 12:41:51.796000'), 12, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 12:41:51.796000'), 12, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 12:45:52.796000'), 12, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 12:47:49.796000'), 12, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 12:50:26.796000'), 12, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 12:53:55.796000'), 12, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:00:59.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:03:03.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:04:41.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:08:53.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:12:16.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:15:13.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:17:23.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:17:30.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:21:17.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:21:21.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:27:46.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:28:12.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:29:23.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:29:46.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:30:49.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:31:37.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:33:10.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:33:24.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:37:12.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:41:18.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:44:29.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:45:35.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:48:19.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:49:00.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:52:34.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:52:40.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:53:50.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:54:24.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:56:47.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:57:30.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 13:58:44.796000'), 13, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:00:53.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:00:58.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:00:59.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:01:07.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:04:35.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:05:27.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:07:13.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:08:14.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:09:22.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:13:08.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:13:10.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:16:50.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:16:52.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:17:10.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:20:21.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:20:52.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:21:51.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:22:57.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:24:22.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:25:39.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:26:02.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:26:29.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:29:37.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:30:20.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:30:59.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:32:34.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:33:03.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:34:48.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:35:35.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:36:59.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:38:06.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:41:23.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:42:35.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:44:59.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:45:50.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:48:25.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:50:31.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:50:45.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:54:33.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:55:04.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:58:57.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 14:59:02.796000'), 14, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:00:55.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:01:40.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:05:07.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:08:27.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:08:37.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:09:57.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:13:12.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:13:32.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:14:10.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:15:10.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:16:57.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:19:26.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:23:43.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:25:11.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:29:09.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:30:05.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:33:00.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:33:33.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:37:14.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:38:06.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:40:02.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:42:29.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:42:35.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:47:19.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:47:21.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:50:28.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:51:33.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:55:18.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 15:58:48.796000'), 15, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 16:03:13.796000'), 16, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 16:11:01.796000'), 16, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 16:17:56.796000'), 16, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 16:20:07.796000'), 16, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 16:28:21.796000'), 16, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 17:17:50.796000'), 17, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 17:18:57.796000'), 17, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 17:20:58.796000'), 17, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 17:24:39.796000'), 17, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 17:28:08.796000'), 17, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 17:32:31.796000'), 17, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 17:44:15.796000'), 17, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 17:47:35.796000'), 17, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 17:52:03.796000'), 17, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 17:57:02.796000'), 17, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:00:15.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:04:48.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:07:15.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:11:29.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:15:47.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:18:51.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:29:46.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:33:44.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:38:41.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:40:27.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:43:42.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:47:18.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:50:30.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:55:28.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 18:59:18.796000'), 18, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 19:02:33.796000'), 19, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 19:04:22.796000'), 19, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 19:06:07.796000'), 19, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 19:10:42.796000'), 19, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 19:13:56.796000'), 19, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 19:21:12.796000'), 19, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 19:25:15.796000'), 19, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 19:28:21.796000'), 19, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 19:37:30.796000'), 19, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 19:39:49.796000'), 19, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 19:42:09.796000'), 19, 23, 47, 11, 2018, 4]\n",
      "[Timestamp('2018-11-23 21:08:48.796000'), 21, 23, 47, 11, 2018, 4]\n"
     ]
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run `test.ipynb` to see if you've successfully added records to this table."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #4: `users` Table\n",
    "#### Extract Data for Users Table\n",
    "- Select columns for user ID, first name, last name, gender and level and set to `user_df`"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "user_df = df[['userId', 'firstName', 'lastName', 'gender', 'level']].copy()\n",
    "user_df = user_df.drop_duplicates()\n",
    "user_df['userId'] = user_df['userId'].apply(lambda x : int(x) if str(x).isdigit() else None)\n",
    "user_df = user_df.dropna()\n",
    "user_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>gender</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>Arellano</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>63</td>\n",
       "      <td>Ayla</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>58</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Benson</td>\n",
       "      <td>F</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>26</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Smith</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16</td>\n",
       "      <td>Rylan</td>\n",
       "      <td>George</td>\n",
       "      <td>M</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId firstName  lastName gender level\n",
       "0       66     Kevin  Arellano      M  free\n",
       "12      63      Ayla   Johnson      F  free\n",
       "15      58     Emily    Benson      F  paid\n",
       "22      26      Ryan     Smith      M  free\n",
       "24      16     Rylan    George      M  paid"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Insert Records into Users Table\n",
    "Implement the `user_table_insert` query in `sql_queries.py` and run the cell below to insert records for the users in this log file into the `users` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `users` table in the sparkify database."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "for i, row in user_df.iterrows():\n",
    "    cur.execute(user_table_insert, row)\n",
    "    conn.commit()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run `test.ipynb` to see if you've successfully added records to this table."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #5: `songplays` Table\n",
    "#### Extract Data and Songplays Table\n",
    "This one is a little more complicated since information from the songs table, artists table, and original log file are all needed for the `songplays` table. Since the log file does not specify an ID for either the song or the artist, you'll need to get the song ID and artist ID by querying the songs and artists tables to find matches based on song title, artist name, and song duration time.\n",
    "- Implement the `song_select` query in `sql_queries.py` to find the song ID and artist ID based on the title, artist name, and duration of a song.\n",
    "- Select the timestamp, user ID, level, song ID, artist ID, session ID, location, and user agent and set to `songplay_data`\n",
    "\n",
    "#### Insert Records into Songplays Table\n",
    "- Implement the `songplay_table_insert` query and run the cell below to insert records for the songplay actions in this log file into the `songplays` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `songplays` table in the sparkify database."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(row.song)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Your Rocky Spine\n",
      "Va Bien\n",
      "Eleanor Put Your Boots On\n",
      "Float On\n",
      "Aftermath\n",
      "Dok si pored mene\n",
      "Not Enough\n",
      "Everlong\n",
      "Si TÃÂº No EstÃÂ¡s AquÃÂ­\n",
      "All Star\n",
      "Crazy In Love\n",
      "More Than A Woman\n",
      "Yellow\n",
      "Something About You\n",
      "Glittering Prize\n",
      "Don't Cry (Original)\n",
      "Here_ There And Everywhere\n",
      "Buck's Boogie\n",
      "Meddle\n",
      "Tonight\n",
      "Terminal Preppie\n",
      "Pop Champagne\n",
      "What's The Difference\n",
      "To Build A Home\n",
      "Tonight In Flames (Album Version)\n",
      "Numb (Album Version)\n",
      "Nostalgia Amnesia\n",
      "Somebody To Love\n",
      "You're The One\n",
      "Edge Of The Ocean\n",
      "Two Brown Eyes\n",
      "Stretchin' Out (In A Rubber Band) (LP Version)\n",
      "Eenie_ Meenie_ Miney_ Mo\n",
      "Can't Stand Me Now\n",
      "The Penalty\n",
      "Love Is A Losing Game\n",
      "Before I Forget (Album Version)\n",
      "One More Sad Song\n",
      "Paradise City\n",
      "Sehr kosmisch\n",
      "Cold night for alligators\n",
      "Interlude (Milo)\n",
      "Clouds (Of Color Bright Album Version)\n",
      "Burden In My Hand\n",
      "Devour (Album Version)\n",
      "Turn Me Up (Sfaction Version / Feat. Sandy)\n",
      "Tighten Up\n",
      "Jump Then Fall\n",
      "Definitive\n",
      "Me Pregunto\n",
      "Lips Of An Angel\n",
      "Intricacy\n",
      "Ex-Factor\n",
      "The Way I Feel (Not Our Master)\n",
      "Upgrade\n",
      "Moje Mieszkanie\n",
      "Too Shy\n",
      "Can't Keep\n",
      "I Don't Like The Drugs (But The Drugs Like Me)\n",
      "Growing On Me\n",
      "Rabbit Heart (Raise It Up)\n",
      "More Adventurous (Album Version)\n",
      "Get Like Me\n",
      "Cry On (Album Version)\n",
      "Kids Will Be Skeletons\n",
      "Rastafari Is\n",
      "Wish You Well\n",
      "Valley of the Shadows\n",
      "Not Cool Again\n",
      "The New Chapter\n",
      "Back Against The Wall\n",
      "Emily\n",
      "Almaz\n",
      "DVNO\n",
      "ReprÃÂ©sente\n",
      "Try Your Best\n",
      "Out Of Control\n",
      "The Bad Touch\n",
      "O.P.P.\n",
      "Fragile or Possibly Extinct\n",
      "S.O.S. (Message In A Bottle) (Hi_Tack Radio Edit)\n",
      "That's All (2007 Digital Remaster)\n",
      "Stop & Erase\n",
      "Theme\n",
      "Still Alive And Well\n",
      "Long Thin Dawn\n",
      "Take Over The World\n",
      "Gone\n",
      "Honey Wagon\n",
      "Lovely\n",
      "Invierno Del 92\n",
      "Rage!\n",
      "Are You That Somebody? ( LP Version )\n",
      "Stone City Band_ Hi!\n",
      "Clarity\n",
      "The Thousand Names of Lord Shiva (Part 1)\n",
      "Prelude\n",
      "Peace Train\n",
      "Last Day Of Magic\n",
      "Better Now\n",
      "You Only (Acoustic Version)\n",
      "Happy Alone\n",
      "Sorry Or Please\n",
      "Fade To Black\n",
      "A succubus in rapture\n",
      "AmnistÃÂ­a\n",
      "O Canto Da Ema\n",
      "Up Up & Away\n",
      "You Can't Break A Broken Heart\n",
      "Make Love To Your Mind\n",
      "Blessed Be Your Name\n",
      "Stuck (Album Version)\n",
      "War\n",
      "Read My Mind\n",
      "Trying To Find A Balance\n",
      "DÃÂ­a cero\n",
      "Halloween Is Black As Night\n",
      "Masters Of Universe\n",
      "Sky Might Fall\n",
      "Outro\n",
      "Take This To Heart (Album)\n",
      "Totgeliebt\n",
      "Beautiful Stranger\n",
      "Walking Zero\n",
      "Thank You\n",
      "Monster (Album Version)\n",
      "Ill Fated\n",
      "Tight Whips\n",
      "West One (Shine On Me)\n",
      "Human Patterns\n",
      "Dog Days Are Over (Radio Edit)\n",
      "Dry Spell (LP Version)\n",
      "Hardest Of Hearts\n",
      "Fix You\n",
      "In My Place\n",
      "Two Is Better Than One\n",
      "Summerland\n",
      "Always (7'' Mix)\n",
      "This Is The Life\n",
      "Saving Us (Album Version)\n",
      "Jumento Celestino\n",
      "What Do I Know\n",
      "Ela E Carioca\n",
      "La Huella De Tu Mirada\n",
      "What Can I Do?\n",
      "Ready Or Not\n",
      "Behind The Moon\n",
      "Behind Blue Eyes\n",
      "Hardest Of Hearts\n",
      "Black Hole\n",
      "Baby\n",
      "Catch You Baby (Steve Pitron & Max Sanna Radio Edit)\n",
      "Canada\n",
      "Walk Away (Single/LP Version)\n",
      "Undo\n",
      "Love Dog\n",
      "Kiss (LP Version)\n",
      "The Only Exception (Album Version)\n",
      "Le Vin De L'Assassin\n",
      "Dejame Bailar\n",
      "Pursuit Of Happiness (nightmare)\n",
      "Madrugada\n",
      "Living In A Lie\n",
      "Night Divine (On A Search In America Album Version)\n",
      "Never Let You Go\n",
      "Diduntdidunt (featuring Saigon) (Amended Version)\n",
      "Look No Further\n",
      "Heartbeats\n",
      "With You\n",
      "Song For Guy\n",
      "Rabbit Heart (Raise It Up)\n",
      "Latein\n",
      "What's Left of the Flag\n",
      "Boys In The Trees (LP Version)\n",
      "Firestarter\n",
      "Spit It Out [Explicit]\n",
      "Blackpowder Orchard\n",
      "La Prima Cosa Bella\n",
      "Bleed It Out [Live At Milton Keynes]\n",
      "Rain On The Pretty Ones\n",
      "India'Song\n",
      "Rockin Round The World\n",
      "Beautiful Flower\n",
      "Playground\n",
      "Wake Up Call\n",
      "The Time Is Now\n",
      "Undercover Martyn\n",
      "The Greatest [Featuring Mannie Fresh] (Amended Album Version)\n",
      "Le Courage Des Oiseaux\n",
      "What You Wanted\n",
      "Not Ready Yet\n",
      "Let's Spend The Night Together (1999 Digital Remaster)\n",
      "Mr. Man\n",
      "FFT (The Good_ The Bad_ And The Ugly Album Version)\n",
      "Come Away With Me\n",
      "Frijolero\n",
      "Moon Baby\n",
      "Trunk\n",
      "Fade To Black\n",
      "Oliver'S Army\n",
      "Bleed It Out [Live At Milton Keynes]\n",
      "Confrontation\n",
      "Caldonia\n",
      "La Valse D'AmÃÂ©lie (Version Orchestre)\n",
      "Everybody Needs A 303\n",
      "Masterpiece (Album Version)\n",
      "Wordy Rappinghood\n",
      "Goodnight Bad Morning\n",
      "Something (Album Version)\n",
      "Yellow\n",
      "Love And Affection\n",
      "Gone Going\n",
      "My Immortal (bonus)\n",
      "Interlude #1 (Mama)\n",
      "Draw Me Close\n",
      "On Top\n",
      "Some Kind Of Wonderful (Non-Album Track)\n",
      "Sehr kosmisch\n",
      "Honey\n",
      "Suzy Q\n",
      "Robotique Majestique (Album)\n",
      "My Moon My Man\n",
      "Follow Me (Explicit LP Version)\n",
      "Listen To Your Heart (Cologne)\n",
      "8th Of November (Album Version) (w/o Intro)\n",
      "The Writing On My Father\u0019s Hand\n",
      "SinceritÃÂ© Et Jalousie\n",
      "#40\n",
      "Ay Mi Palomita (1997 Digital Remaster)\n",
      "Get Up Off Your Fat\n",
      "Who Was It (Demo Version Of 'EMI')\n",
      "The fluke\n",
      "BorivÃÂ³knak valÃÂ³\n",
      "I'm Not Down\n",
      "Blood On The Motorway\n",
      "Lemonade\n",
      "Misty\n",
      "Our Filmscore\n",
      "Leave It All To Me (Theme from iCarly)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "for index, row in df.iterrows():\n",
    "\n",
    "    # get songid and artistid from song and artist tables\n",
    "    cur.execute(song_select, (row.song, row.artist, row.length))\n",
    "    results = cur.fetchone()\n",
    "    \n",
    "    if results:\n",
    "        songid, artistid = results\n",
    "    else:\n",
    "        songid, artistid = None, None\n",
    "\n",
    "    # insert songplay record\n",
    "    songplay_data = (row.ts, row.userId, row.level, songid, artistid, row.sessionId, row.location, row.userAgent)\n",
    "    cur.execute(songplay_table_insert, songplay_data)\n",
    "    conn.commit()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run `test.ipynb` to see if you've successfully added records to this table."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Close Connection to Sparkify Database"
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "conn.close()"
   ],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implement `etl.py`\n",
    "Use what you've completed in this notebook to implement `etl.py`."
   ],
   "metadata": {
    "editable": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "editable": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}